{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport cv2 as cv\nimport torch\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics.functional import precision_recall\n# from sklearn.metrics import confusion_matrix\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport os\nimport pickle\nfrom sklearn.model_selection import train_test_split\nfrom skimage.transform import resize\nfrom sklearn.metrics import f1_score\nimport os\nimport random\nimport cv2 as cv\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = '../input/aptos2019-blindness-detection/train_images'\nTRAIN_CSV = '../input/aptos2019-blindness-detection/train.csv'\ntrain_df = pd.read_csv(TRAIN_CSV)\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.isna().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img1 = cv.imread('../input/aptos2019-blindness-detection/train_images/000c1434d8d7.png')\nprint(train_img1.shape)\nplt.imshow(train_img1)\n\nseen = []\nfor i in range(len(train_df)):\n    img_fname = '../input/aptos2019-blindness-detection/train_images/' + train_df['id_code'][i] + '.png'\n    img = cv.imread(img_fname)\n    shape = img.shape\n    if img.shape not in set(seen):\n        seen.append(img.shape)\n        \nprint(len(seen))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RetinopathyDataset(Dataset):\n    def __init__(self, label_df, img_dir):\n        self.imgs = [img_dir + '/' + fname + '.png' for fname in label_df['id_code']]\n        self.labels = [label for label in label_df['diagnosis']]\n        \n    def __len__(self):\n        return len(self.imgs)\n        \n    def __getitem__(self, i):\n        img_arr = cv.imread(self.imgs[i])[:, 500:3000]\n        \n#         plt.imshow(img_arr)\n        \n        img_arr = resize(img_arr, (100, 100, 3)) * 255\n        \n        \n        \n        if np.max(img_arr) > 1:\n            img_arr = img_arr/255.0\n\n      # Reverse last three dimensions to get the shape: frame * rgb * h * w\n        img_arr = np.moveaxis(img_arr, -1, 0)\n#         print(img_arr.shape)\n\n        \n#         print(self.imgs[i], self.labels[i])\n        return img_arr, self.labels[i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = RetinopathyDataset(train_df[:(int(0.8 * len(train_df)))], TRAIN_DIR)\ntrain_loader = DataLoader(dataset = train_data, batch_size = 16)\n\ntest_data = RetinopathyDataset(train_df[int(0.8 * len(train_df)):], TRAIN_DIR)\ntest_loader = DataLoader(dataset = test_data, batch_size = 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\nresnet = models.resnet50(pretrained = True)\n\nprint(resnet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IntensityDetector(nn.Module):\n    def __init__(self):\n        super(IntensityDetector, self).__init__()\n        \n        self.feature_extractor = models.resnet50(pretrained = True)\n        for param in self.feature_extractor.parameters():\n            param.requires_grad = False\n            \n        self.feature_extractor.fc = nn.Linear(in_features = 2048, out_features = 5, bias = True)  \n        \n    def forward(self, x):\n        return self.feature_extractor(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = IntensityDetector()\nmodel.to(device)\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(),\n lr=0.06, momentum=0.9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calcMetrics(model, set_loader, file_name):\n    y_pred = []\n    y_true = []\n    total = 0.0\n\n  # visualize_filters()\n\n  # accuracy = accuracy.cuda()\n    with torch.no_grad():\n        for data in set_loader:\n            images, labels = data\n              # run the model on the test set to predict labels\n            outputs = model(images.float().cuda())\n              # the label with the highest energy will be our prediction\n            _, predicted = torch.max(outputs.cuda().data, 1)\n\n        for label, pred in list(zip(labels, predicted)):\n            y_pred.append(pred.item())\n            y_true.append(label.item())\n\n  \n    #   plot_confusion_matrix(y_true, y_pred, file_name)\n    # precision_recall(torch.Tensor(y_pred).int().cuda(), torch.Tensor(y_true).int().cuda(), average='macro', num_classes=4)\n\n    return f1_score(y_true, y_pred, average = 'macro')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs):\n    best_acc = 0.0\n    \n    for epoch in range(epochs):\n        running_loss = 0.0\n        \n        for i, (img, label) in enumerate(train_loader):\n            img.to(device)\n            label.to(device)\n            \n            optimizer.zero_grad()\n            \n            outputs = model(img.float().cuda())\n            \n            loss = loss_fn(outputs.cuda(), label.cuda())\n            \n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            if i % 100:\n                print('EPOCH %d loss: %f' %\n                      (epoch + 1, running_loss / len(img)))\n                running_loss = 0.0\n            \n#             file_name = f\"/content/drive/MyDrive/cmatrix_epoch_test_{epoch}.png\"\n        test_acc = calcMetrics(model, test_loader, \"test.png\")\n        f1_score = test_acc\n        print('Test F1 score:', f1_score)\n#         print('Precision:', pre_recall[0].item())\n#         print('Recall:', pre_recall[1].item())\n        print('-------------------------------------')\n        print('-------------------------------------')\n        \n        if best_acc < f1_score:\n            best_acc = f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(model, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}